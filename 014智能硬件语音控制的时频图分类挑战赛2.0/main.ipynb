{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIstudio链接：https://aistudio.baidu.com/aistudio/projectdetail/4415367\n",
    "\n",
    "赛事链接：https://challenge.xfyun.cn/topic/info?type=time-frequency-2022&option=tjjg\n",
    "\n",
    "数据可以在赛事链接下载\n",
    "\n",
    "参考：\n",
    "- https://developer.aliyun.com/article/1081903\n",
    "- https://www.bilibili.com/video/BV1zj411K79W/?p=50&vd_source=58d010759cc2b1d5bc7753dd8aad0710"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一. 赛事介绍\n",
    "赛事链接：[https://challenge.xfyun.cn/topic/info?type=time-frequency-2022&option=tjjg](https://challenge.xfyun.cn/topic/info?type=time-frequency-2022&option=tjjg)\n",
    "\n",
    "本次竞赛是一次典型的图像分类竞赛，通过训练已知的图片及其对应标签，预测得到未知图片的种类。\n",
    "\n",
    "官方提供的数据集为以下格式：\n",
    "\n",
    "- **test**：存放将要预测的测试集图片；\n",
    "- **train**：存放训练集图片；\n",
    "- **train.csv**：存放训练集图片的路径及其对应的类别；\n",
    "- **提交示例**：存放测试集图片的路径及其预测得到的类别。\n",
    "\n",
    "下面我基于**百度飞桨**深度学习框架，提供了三种模型训练、预测、生成结果文件的全流程baseline，该baseline亦可用于所有图像分类竞赛，只需要针对性地修改Dataset中图片和标签的读取方式即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-30 16:40:17--  https://ai-contest-static.xfyun.cn/2022/%E6%95%B0%E6%8D%AE%E9%9B%86/%E6%99%BA%E8%83%BD%E7%A1%AC%E4%BB%B6%E8%AF%AD%E9%9F%B3%E6%8E%A7%E5%88%B6%E7%9A%84%E6%97%B6%E9%A2%91%E5%9B%BE%E5%88%86%E7%B1%BB%E6%8C%91%E6%88%98%E8%B5%9B%E5%85%AC%E5%BC%80%E6%95%B0%E6%8D%AE.zip\n",
      "Resolving ai-contest-static.xfyun.cn (ai-contest-static.xfyun.cn)... 118.123.235.2, 125.64.92.198\n",
      "Connecting to ai-contest-static.xfyun.cn (ai-contest-static.xfyun.cn)|118.123.235.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 472229467 (450M) [application/zip]\n",
      "Saving to: ‘智能硬件语音控制的时频图分类挑战赛公开数据.zip’\n",
      "\n",
      "100%[======================================>] 472,229,467 7.95MB/s   in 59s    \n",
      "\n",
      "2024-03-30 16:41:16 (7.68 MB/s) - ‘智能硬件语音控制的时频图分类挑战赛公开数据.zip’ saved [472229467/472229467]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://ai-contest-static.xfyun.cn/2022/%E6%95%B0%E6%8D%AE%E9%9B%86/%E6%99%BA%E8%83%BD%E7%A1%AC%E4%BB%B6%E8%AF%AD%E9%9F%B3%E6%8E%A7%E5%88%B6%E7%9A%84%E6%97%B6%E9%A2%91%E5%9B%BE%E5%88%86%E7%B1%BB%E6%8C%91%E6%88%98%E8%B5%9B%E5%85%AC%E5%BC%80%E6%95%B0%E6%8D%AE.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#解压数据集 \n",
    "!unzip -O GBK -oq data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#导入所需库\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import paddle\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddle.regularizer import L2Decay\n",
    "import paddle.nn as nn\n",
    "from paddle.vision import transforms\n",
    "from paddle.vision import models\n",
    "from paddle.metric import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0\n"
     ]
    }
   ],
   "source": [
    "#环境设置\n",
    "device  = paddle.device.get_device()\n",
    "#输出cuda说明使用gpu，输出cpu说明使用cpu，最好使用gpu训练\n",
    "paddle.device.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#原始数据读取\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df['path'] = 'data/train/' + train_df['image']\n",
    "train_df.sample(frac=1).reset_index(drop=True) #打乱训练集\n",
    "\n",
    "test_df = pd.read_csv('data/提交示例.csv')\n",
    "test_df['path'] = 'data/test/' + test_df['image'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#定义数据集读取方法：\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, label, transforms=None):        \n",
    "        self.img_path = img_path        \n",
    "        self.label = label        \n",
    "        if transforms is not None:           \n",
    "            self.transforms = transforms        \n",
    "        else:            \n",
    "            self.transforms = None        \n",
    "    def __getitem__(self, index):        \n",
    "        img = img = Image.open(self.img_path[index]).convert('RGB')  \n",
    "        img = self.transforms(img)                                    \n",
    "        \n",
    "        return img,self.label[index]        \n",
    "    \n",
    "    def __len__(self):        \n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 基础API训练(分数：0.82左右 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 训练数据的分割、特征工程及封装\n",
    "此部分主要包括三个步骤：\n",
    "- 分割训练数据，其中1943张用于训练，200张用于验证；\n",
    "- 对训练集和验证集做数据预处理，对训练集做特征工程；\n",
    "- 生成训练集和验证集的Dataloader，用于训练时批量数据读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#使用torch批量数据读取\n",
    "train_loader = DataLoader(    \n",
    "    XunFeiDataset(train_df['path'].values[:-200], train_df['label'].values[:-200],           \n",
    "            transforms.Compose([\n",
    "                transforms.Resize(256), \n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "            ])\n",
    "        ), batch_size=4, shuffle=True, num_workers=0)\n",
    "    \n",
    "val_loader = DataLoader(    \n",
    "    XunFeiDataset(train_df['path'].values[-200:], train_df['label'].values[-200:],            \n",
    "            transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "        ), batch_size=2, shuffle=False, num_workers=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 定义模型、损失函数和优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0330 18:12:00.881722 49154 gpu_resources.cc:96] The GPU architecture in your current machine is Pascal, which is not compatible with Paddle installation with arch: 70 75 80 86 , it is recommended to install the corresponding wheel package according to the installation information on the official Paddle website.\n",
      "W0330 18:12:00.881780 49154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.3, Runtime API Version: 11.7\n",
      "W0330 18:12:00.882212 49154 dynamic_loader.cc:303] The third-party dynamic library (libcudnn.so) that Paddle depends on is not configured correctly. (error code is /usr/local/cuda/lib64/libcudnn.so: cannot open shared object file: No such file or directory)\n",
      "  Suggestions:\n",
      "  1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\n",
      "  2. Configure third-party dynamic library environment variables as follows:\n",
      "  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\n",
      "  - Windows: set PATH by `set PATH=XXX;\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "(PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\n  [Hint: cudnn_dso_handle should not be null.] (at ../paddle/phi/backends/dynload/cudnn.cc:64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, parameters\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(),weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/vision/models/resnet.py:399\u001b[0m, in \u001b[0;36mresnet18\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresnet18\u001b[39m(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"ResNet 18-layer model from\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m            # [1, 1000]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresnet18\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBasicBlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/vision/models/resnet.py:352\u001b[0m, in \u001b[0;36m_resnet\u001b[0;34m(arch, Block, depth, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resnet\u001b[39m(arch, Block, depth, pretrained, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 352\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    355\u001b[0m             arch \u001b[38;5;129;01min\u001b[39;00m model_urls\n\u001b[1;32m    356\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m model do not have a pretrained model now, you should set pretrained=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    357\u001b[0m             arch\n\u001b[1;32m    358\u001b[0m         )\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/vision/models/resnet.py:264\u001b[0m, in \u001b[0;36mResNet.__init__\u001b[0;34m(self, block, depth, width, num_classes, with_pool, groups)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplanes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplanes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_norm_layer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplanes)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/nn/layer/conv.py:685\u001b[0m, in \u001b[0;36mConv2D.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, padding_mode, weight_attr, bias_attr, data_format)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    673\u001b[0m     in_channels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    683\u001b[0m     data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCHW\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    684\u001b[0m ):\n\u001b[0;32m--> 685\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/nn/layer/conv.py:156\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, transposed, dims, stride, padding, padding_mode, output_padding, dilation, groups, weight_attr, bias_attr, data_format)\u001b[0m\n\u001b[1;32m    153\u001b[0m     std \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m/\u001b[39m filter_elem_num) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Normal(\u001b[38;5;241m0.0\u001b[39m, std)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_parameter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_param_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_default_param_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_parameter(\n\u001b[1;32m    162\u001b[0m     attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bias_attr, shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_channels], is_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    163\u001b[0m )\n\u001b[1;32m    165\u001b[0m cudnn_version \u001b[38;5;241m=\u001b[39m get_cudnn_version()\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/nn/layer/layers.py:715\u001b[0m, in \u001b[0;36mLayer.create_parameter\u001b[0;34m(self, shape, attr, dtype, is_bias, default_initializer)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(temp_attr, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m temp_attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    714\u001b[0m     temp_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_parameter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_initializer\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/fluid/layer_helper_base.py:424\u001b[0m, in \u001b[0;36mLayerHelperBase.create_parameter\u001b[0;34m(self, attr, shape, dtype, is_bias, default_initializer, stop_gradient, type)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_used:\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    419\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter name [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] have be been used. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn dygraph mode, the name of parameter can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be same.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    421\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the parameter attr value passed to self.create_parameter or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstructor of dygraph Layers\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(attr\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    423\u001b[0m         )\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_program\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_parameter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_gradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwith_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartup_program\u001b[38;5;241m.\u001b[39mglobal_block()\u001b[38;5;241m.\u001b[39mcreate_parameter(\n\u001b[1;32m    433\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    434\u001b[0m         shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattr\u001b[38;5;241m.\u001b[39m_to_kwargs(with_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    437\u001b[0m     )\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/fluid/framework.py:3935\u001b[0m, in \u001b[0;36mBlock.create_parameter\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3933\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   3934\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3935\u001b[0m         \u001b[43minitializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3936\u001b[0m param\u001b[38;5;241m.\u001b[39mstop_gradient \u001b[38;5;241m=\u001b[39m stop_gradient\n\u001b[1;32m   3937\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m param\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/nn/initializer/initializer.py:40\u001b[0m, in \u001b[0;36mInitializer.__call__\u001b[0;34m(self, param, block)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, param, block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lazy_init_helper()\u001b[38;5;241m.\u001b[39mstate:\n\u001b[0;32m---> 40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(param, block)\n",
      "File \u001b[0;32m/data1/ckw/micromamba/envs/paddle/lib/python3.11/site-packages/paddle/nn/initializer/normal.py:71\u001b[0m, in \u001b[0;36mNormalInitializer.forward\u001b[0;34m(self, var, block)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_dygraph_mode():\n\u001b[1;32m     70\u001b[0m     place \u001b[38;5;241m=\u001b[39m _current_expected_place()\n\u001b[0;32m---> 71\u001b[0m     out_var \u001b[38;5;241m=\u001b[39m \u001b[43m_C_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_std_dev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     out_var\u001b[38;5;241m.\u001b[39m_share_underline_tensor_to(var)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: (PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\n  [Hint: cudnn_dso_handle should not be null.] (at ../paddle/phi/backends/dynload/cudnn.cc:64)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True,num_classes=24)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=0.0001, parameters=model.parameters(),weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#----------------模型训练----------------      \n",
    "# 模型训练一个epoch的函数\n",
    "def train(train_loader, model, criterion, optimizer):   \n",
    "    model.train()  \n",
    "    train_acc = 0.0  \n",
    "    train_loss = 0.0    \n",
    "    \n",
    "    for i, (input, target) in enumerate(train_loader):               \n",
    "        output = model(input)        \n",
    "        loss = criterion(output, target)        \n",
    "        optimizer.clear_grad()        \n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        if i % 40 == 0:            \n",
    "            print(loss.item())\n",
    "        train_acc += (output.argmax(1) == target).sum().item()                             \n",
    "        train_loss += loss.item()        \n",
    "    \n",
    "    return train_loss/len(train_loader),train_acc / len(train_loader.dataset)\n",
    "    \n",
    "# 模型验证一个epoch的函数\n",
    "def validate(val_loader, model, criterion):    \n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0        \n",
    "    \n",
    "    with paddle.no_grad():        \n",
    "        end = time.time()        \n",
    "        for i, (input, target) in enumerate(val_loader):                        \n",
    "            output = model(input)            \n",
    "            val_loss += criterion(output, target).item()\n",
    "            val_acc += (output.argmax(1) == target).sum().item()                   \n",
    "        return val_loss/len(val_loader),val_acc / len(val_loader.dataset)            \n",
    "\n",
    "epochs = 40\n",
    "for i  in range(epochs):\n",
    "    print(\"------epoch{}----------\".format(i))   \n",
    "    print(\"-------Loss----------\")      \n",
    "    train_loss,train_acc = train(train_loader, model, criterion, optimizer) \n",
    "    print(\"loss={}\".format(train_loss))  \n",
    "    print(\"acc:{}\".format(train_acc)) \n",
    "\n",
    "    print(\"-------Val acc----------\") \n",
    "    val_loss,val_acc = validate(val_loader, model, criterion)  \n",
    "    print(\"loss={}\".format(val_loss))  \n",
    "    print(\"acc:{}\".format(val_acc))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 模型预测及结果输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#----------------模型预测----------------\n",
    "test_loader = DataLoader(    \n",
    "    XunFeiDataset(test_df['path'].values, [0] * test_df.shape[0],            \n",
    "        transforms.Compose([\n",
    "                transforms.Resize((224, 224)),        \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "            ), batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "model.eval()    \n",
    "val_acc = 0.0        \n",
    "\n",
    "test_pred = []    \n",
    "with paddle.no_grad():  \n",
    "    for input, _ in test_loader():\n",
    "        # print(img[0])                      \n",
    "        output = model(input)           \n",
    "        test_pred.append(output.cpu().numpy())                \n",
    "\n",
    "pred = np.vstack(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#----------------结果输出----------------\n",
    "pd.DataFrame(    \n",
    "    {        \n",
    "        'image': [x.split('/')[-1] for x in test_df['path'].values],        \n",
    "        'label': pred.argmax(1)\n",
    "        }).to_csv('result.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行后生成名为**result.csv**的文件，提交该文件至平台即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 K折交叉验证(分数：0.85左右)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 训练数据的分割、特征工程及封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# K折交叉验证\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = X_train.append(X_part)\n",
    "            y_train = y_train.append(y_part)\n",
    "    train_loader = DataLoader(XunFeiDataset(X_train.values, y_train.values,           \n",
    "                                    transforms.Compose([\n",
    "                                        transforms.Resize(224), #256\n",
    "                                        #transforms.RandomHorizontalFlip(),\n",
    "                                        #transforms.RandomCrop(224), \n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "                            ), batch_size=4, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(XunFeiDataset(X_valid.values, y_valid.values,            \n",
    "                                transforms.Compose([\n",
    "                                    transforms.Resize(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "                            ), batch_size=2, shuffle=False, num_workers=0) \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此部分主要包括三个步骤：\n",
    "- 将训练数据分成k份，取其中第i份为验证集，其余为训练集；\n",
    "- 对训练集和验证集做数据预处理，对训练集做特征工程；\n",
    "- 生成训练集和验证集的Dataloader，用于训练时批量数据读取。\n",
    "\n",
    "函数`get_k_fold_data(k, i, X, y)`的输入参数分别表示：\n",
    "\n",
    "- **k**：将训练数据分成k份；\n",
    "- **i**：设置其中第i份为验证集，其余为训练集；\n",
    "- **x**：训练数据的图片地址，为`Series`数据类型；\n",
    "- **y**：训练数据的标签，为`Series`数据类型。\n",
    "\n",
    "函数的输出为**训练集和验证集的Dataloader**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []       \n",
    "#----------------模型训练----------------\n",
    "       \n",
    "# 模型训练一个epoch的函数\n",
    "def train(train_loader, model, criterion, optimizer):   \n",
    "    model.train()  \n",
    "    train_acc = 0.0  \n",
    "    train_loss = 0.0    \n",
    "    \n",
    "    for i, (input, target) in enumerate(train_loader):               \n",
    "        output = model(input)        \n",
    "        loss = criterion(output, target)        \n",
    "        optimizer.clear_grad()        \n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        if i % 40 == 0:            \n",
    "            print(loss.item())\n",
    "        train_acc += (output.argmax(1) == target).sum().item()                             \n",
    "        train_loss += loss.item()        \n",
    "    \n",
    "    return train_loss/len(train_loader.dataset),train_acc / len(train_loader.dataset)\n",
    "    \n",
    "# 模型验证一个epoch的函数\n",
    "def validate(val_loader, model, criterion):    \n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0        \n",
    "    \n",
    "    with paddle.no_grad():        \n",
    "        end = time.time()        \n",
    "        for i, (input, target) in enumerate(val_loader):                        \n",
    "            output = model(input)            \n",
    "            val_loss += criterion(output, target).item()\n",
    "            val_acc += (output.argmax(1) == target).sum().item()                   \n",
    "        return val_loss/len(val_loader.dataset),val_acc / len(val_loader.dataset)    \n",
    "\n",
    "# 模型预测函数     \n",
    "def predict(test_loader, model, criterion):    \n",
    "    model.eval()    \n",
    "    val_acc = 0.0        \n",
    "\n",
    "    test_pred = []    \n",
    "    with paddle.no_grad():        \n",
    "        end = time.time()        \n",
    "        for i, (input, target) in enumerate(test_loader):                \n",
    "            output = model(input)            \n",
    "            test_pred.append(output.cpu().numpy())                \n",
    "        return np.vstack(test_pred)\n",
    "        \n",
    "test_loader = DataLoader(    \n",
    "    XunFeiDataset(test_df['path'].values, [0] * test_df.shape[0],            \n",
    "        transforms.Compose([\n",
    "                transforms.Resize((224, 224)),        \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "            ), batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "# 模型训练\n",
    "k_fold = 5\n",
    "for i in range(k_fold):\n",
    "    train_loss_mean = 0.0\n",
    "    train_acc_mean = 0.0\n",
    "    val_loss_mean = 0.0\n",
    "    val_acc_mean = 0.0\n",
    "\n",
    "    train_loader,val_loader = get_k_fold_data(k_fold, i, train_df['path'], train_df['label'])\n",
    "    model = models.resnet18(pretrained=True,num_classes=24)\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\toptimizer = paddle.optimizer.Adam(learning_rate=0.0001, parameters=model.parameters(),weight_decay=0.1)\n",
    "\t\n",
    "    print(\"---------第{}折开始----------\".format(i+1))\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        print(\"------epoch{}----------\".format(epoch))   \n",
    "        print(\"-------Loss----------\")      \n",
    "        train_loss,train_acc = train(train_loader, model, criterion, optimizer) \n",
    "        train_loss_mean += train_loss/epochs\n",
    "        train_acc_mean += train_acc/epochs\n",
    "        print(\"loss={}\".format(train_loss))  \n",
    "        print(\"acc:{}\".format(train_acc)) \n",
    "\n",
    "        print(\"-------Val acc----------\") \n",
    "        val_loss,val_acc = validate(val_loader, model, criterion) \n",
    "        val_loss_mean += val_loss/epochs\n",
    "        val_acc_mean += val_acc/epochs \n",
    "        print(\"loss={}\".format(val_loss))  \n",
    "        print(\"acc:{}\".format(val_acc)) \n",
    "    print(\"第{}折交叉验证train_loss={},train_acc={},val_loss={},val_acc={}\".format(i+1,train_loss_mean,train_acc_mean,val_loss_mean,val_acc_mean))\n",
    "    \n",
    "#----------------模型测试----------------\n",
    "#1. result为每一折测试集预测得到五组种类组合成的Dataframe\n",
    "#2. pred为每一折测试集得到的原始结果相加\n",
    "    test_pred = predict(test_loader, model, criterion)\n",
    "    result[str(i)] = test_pred.argmax(1)\n",
    "    if i==0:\n",
    "        pred = test_pred\n",
    "    else:\n",
    "        pred += test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 模型预测及结果输出\n",
    "在每一折训练结束之后都对测试集进行了一次预测，我这里提供了两种方式：\n",
    "\n",
    "- **result**：为每一折测试集预测得到k组种类组合成的Dataframe。比如测试集有1020张图片，k为5折，则result为大小为(1020,5)，其中每一列为每一折模型预测得到1020张图片对应的种类，最终对每一张图片进行投票，选取预测最多的种类作为该图片的类。\n",
    "- **pred**：为每一折测试集得到的原始结果相加，大小为(1020,24)的Array数组，其中每一行为每一张图片对应24个种类的分数，选取分数最高的作为该图片的类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#----------------结果输出----------------\n",
    "#保存五次预测投票后的结果\n",
    "label = np.array(result.mode(1)[0],dtype=int)\n",
    "pd.DataFrame(    \n",
    "    {        \n",
    "        'image': [x.split('/')[-1] for x in test_df['path'].values],        \n",
    "        'label': pred.argmax(1)\n",
    "        }).to_csv('result.csv', index=None)\n",
    "        \n",
    "#保存五次预测的原始结果(1020*24)求和后每一个样本的最大分数对应的类\n",
    "pd.DataFrame(    \n",
    "    {        \n",
    "        'image': [x.split('/')[-1] for x in test_df['path'].values],        \n",
    "        'label': pred.argmax(1)\n",
    "        }).to_csv('result2.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这两种预测方式得到的结果大部分是相同的，有可能有小部分图片的结果有所差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 高层API训练(分数：0.80左右 )\n",
    "关于高层API参考：[官方文档](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#fit-train-data-none-eval-data-none-batch-size-1-epochs-1-eval-freq-1-log-freq-10-save-dir-none-save-freq-1-verbose-2-drop-last-false-shuffle-true-num-workers-0-callbacks-none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 训练数据的分割、特征工程及封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset =  XunFeiDataset(train_df['path'].values[:-200], train_df['label'].values[:-200],           \n",
    "            transforms.Compose([\n",
    "                transforms.Resize(224), #256\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                #transforms.RandomCrop(224), \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "            )\n",
    "val_dataset = XunFeiDataset(train_df['path'].values[-200:], train_df['label'].values[-200:],            \n",
    "            transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 定义模型、损失函数和优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 模型定义这个跟前面有点不一样\n",
    "model = paddle.Model(models.resnet18(pretrained=True,num_classes=24))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=0.0001, parameters=model.parameters(),weight_decay=0.1)\n",
    "\n",
    "# 进行训练前准备\n",
    "model.prepare(optimizer, criterion , Accuracy(topk=(1, 5))) #Accuracy(topk=(1, 5))表示输出预测得到Top1和Top5的准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 启动训练，更多输入参考官方文档\n",
    "model.fit(train_dataset,\n",
    "          val_dataset,\n",
    "          epochs=50,\n",
    "          batch_size=4,\n",
    "          save_dir=\"./output\", #模型保存路径\n",
    "          num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每一轮训练后的模型参数保存在`\"./output\"`文件夹下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#模型评估\n",
    "model.load(\"./output/48\") #加载模型参数\n",
    "model.evaluate(val_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 模型预测及结果输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "test_dataset = XunFeiDataset(test_df['path'].values, [0] * test_df.shape[0],            \n",
    "        transforms.Compose([\n",
    "                transforms.Resize((224, 224)),        \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "            )\n",
    "test_result = model.predict(test_dataset,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#结果输出\n",
    "label = []\n",
    "for i in range(len(test_result[0])):\n",
    "    label.append(test_result[0][i].argmax())\n",
    "pd.DataFrame(    \n",
    "    {        \n",
    "        'image': [x.split('/')[-1] for x in test_df['path'].values],        \n",
    "        'label': label\n",
    "        }).to_csv('result.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三. 最后\n",
    "本文提供了图像分类竞赛的三种baseline，对于不同的数据集仅需要修改Dataset中图片和标签的读取方式即可，大家可以在此基础上通过修改特征工程、模型、学习率等操作提升分数，如果大家有好的分数提高的方法麻烦评论或者私信我一起学习分享，谢谢大家！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  自我介绍\n",
    "\n",
    "> 华中科技大学  人工智能与自动化学院  控制科学与工程专业  准研一\n",
    "\n",
    "> 在AI方面做过的项目不多，去年参加全国大学生智能汽车竞赛百度智慧交通赛项开始接触AI和飞桨，在AI领域还是处于学习和探索阶段，欢迎大家与我交流！\n",
    "\n",
    ">CSDN主页：[https://blog.csdn.net/cyj972628089?spm=1010.2135.3001.5343](https://blog.csdn.net/cyj972628089?spm=1010.2135.3001.5343)\n",
    "\n",
    ">AIstudio主页：[https://aistudio.baidu.com/aistudio/usercenter](https://aistudio.baidu.com/aistudio/usercenter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "paddle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
